{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1f505-04be-406e-ad8a-5535a8475db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:22:27.920993200Z",
     "start_time": "2024-05-14T08:22:21.278896100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from models import CustomGCNConv\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167447532f3bb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:28:45.616799400Z",
     "start_time": "2024-05-14T08:22:27.923987800Z"
    },
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the training graphs\n",
    "filenames = os.listdir('init_node_embedding_train_graphs')\n",
    "train_graphs = []\n",
    "for filename in filenames:\n",
    "    file_path = os.path.join('init_node_embedding_train_graphs', filename)\n",
    "    g = nx.read_edgelist(file_path, nodetype=int, create_using=nx.DiGraph)\n",
    "    # Set the edge weight to 1/in_degree\n",
    "    for u, v, a in g.edges(data=True):\n",
    "        a['weight'] = 1 / len(list(g.predecessors(v)))\n",
    "    train_graphs.append(g)\n",
    "\n",
    "# Construct training data\n",
    "num_features = 64\n",
    "device = torch.device('cuda')\n",
    "data_list = []\n",
    "# Select different initial vectors and edge_index for x according to the different graphs\n",
    "with tqdm(total=len(train_graphs), desc='Generate training data', file=sys.stdout) as bar:\n",
    "    for i, graph in enumerate(train_graphs):\n",
    "        graph_edge_index, graph_edge_weight = utils.get_graph_edge_index(graph, True)\n",
    "        y_g = np.zeros(graph.number_of_nodes(), dtype=float)\n",
    "        for node in graph.nodes():\n",
    "            y_g[node] = utils.computeMC(graph, [node], 10000) / graph.number_of_nodes()\n",
    "\n",
    "        y = y_g\n",
    "        y = (y - y.min()) / (y.max() - y.min())\n",
    "        \n",
    "        y = torch.tensor(y, dtype=torch.float)\n",
    "        x = torch.ones(graph.number_of_nodes(), num_features * 2, dtype=torch.float)\n",
    "        edge_index = torch.tensor(graph_edge_index, dtype=torch.long)\n",
    "        edge_weight = torch.tensor(graph_edge_weight, dtype=torch.float)\n",
    "        data = Data(x, edge_index, y=y, edge_weight=edge_weight).to(device)\n",
    "        data_list.append(data)\n",
    "        bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a67ffbf2ad0ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:31:10.542639200Z",
     "start_time": "2024-05-14T08:31:10.462754300Z"
    },
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NodeEncoder(nn.Module):\n",
    "    def __init__(self, num_features, T=3):\n",
    "        super(NodeEncoder, self).__init__()\n",
    "        self.convs1 = nn.Sequential()\n",
    "        self.convs2 = nn.Sequential()\n",
    "        for i in range(T):\n",
    "            self.convs1.add_module(f'conv_1_{i}', CustomGCNConv(num_features, num_features))\n",
    "            self.convs2.add_module(f'conv_2_{i}', CustomGCNConv(num_features, num_features))\n",
    "        self.w1 = nn.Linear(num_features, num_features, bias=False)\n",
    "        self.w2 = nn.Linear(num_features, num_features, bias=False)\n",
    "        self.fc1 = nn.Linear(2 * num_features, 2 * num_features)\n",
    "        self.fc2 = nn.Linear(2 * num_features, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x1 = x[:, x.shape[1]//2:]\n",
    "        x2 = x[:, :x.shape[1]//2]\n",
    "        for i, (conv1, conv2) in enumerate(zip(self.convs1, self.convs2)):\n",
    "            x1 = F.leaky_relu(conv1(x1, edge_index[[1, 0]], edge_weight, 0.0 if i == 0 else 1.0), 0.2)\n",
    "            x2 = F.leaky_relu(conv2(x2, edge_index, edge_weight, 0.0 if i == 0 else 1.0), 0.2)\n",
    "        x = self.fc1(torch.cat([self.w1(x1), self.w2(x2)], dim=-1))\n",
    "        y = x\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2).view(-1)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe94d1b63f4630a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:32:59.257577Z",
     "start_time": "2024-05-14T08:32:47.655428900Z"
    },
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "train_iter = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n",
    "model = NodeEncoder(num_features=num_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# train\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_iter:\n",
    "        # print(type(data.y))\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.edge_weight)[0]\n",
    "        loss = F.mse_loss(out, data.y)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018b7362574172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:32:59.445604600Z",
     "start_time": "2024-05-14T08:32:59.262113700Z"
    },
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Draw a loss change chart\n",
    "plt.plot(range(1, len(loss_list)+1), loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470602a170e98d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:54:38.884271500Z",
     "start_time": "2024-05-14T08:54:38.848274200Z"
    },
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../node_encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232b2dc-7a92-41c0-bd47-77beae6696a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
